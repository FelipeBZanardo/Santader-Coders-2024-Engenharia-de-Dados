{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae1c7c2c-0442-430e-9e31-1c3404ec4855",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Apache Kafka\n",
    "\n",
    "##  O que é Apache Kafka?\n",
    "Apache Kafka é uma plataforma de streaming distribuído, usada principalmente para construir pipelines de dados e sistemas de mensagens em tempo real. Foi desenvolvido pela LinkedIn e depois doado para a Apache Foundation. Kafka tem várias funcionalidades importantes:\n",
    "\n",
    "- Pub/Sub: Segue o modelo publisher/subscriber (produtor/consumidor).\n",
    "- Escalabilidade: Alta escalabilidade horizontal.\n",
    "- Persistência: Armazena mensagens de forma distribuída e resiliente.\n",
    "- Baixa latência: Excelente para processar fluxos de dados em tempo real.\n",
    "##  Conceitos Principais do Kafka\n",
    "- Produtor: Uma aplicação que envia mensagens para o Kafka.\n",
    "- Consumidor: Uma aplicação que lê mensagens do Kafka.\n",
    "- Tópicos: Um tópico é um canal para onde as mensagens são enviadas. É uma forma de categorizar as mensagens.\n",
    "- Partições: Cada tópico pode ser dividido em várias partições para permitir escalabilidade.\n",
    "- Brokers: Servidores Kafka que armazenam as mensagens.\n",
    "- Zookeeper: Usado para coordenar os brokers no Kafka (em versões mais recentes, o Kafka pode funcionar sem Zookeeper).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47473ae1-314d-4e0f-ad35-b01d2230d5dd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### **Brokers no Apache Kafka**\n",
    "\n",
    "Os **brokers** são os servidores responsáveis por armazenar e gerenciar os dados no cluster Kafka. Eles desempenham funções cruciais no processamento de mensagens e na manutenção de partições dos tópicos, garantindo a **distribuição de carga**, **tolerância a falhas** e **alta disponibilidade**.\n",
    "\n",
    "#### **Principais Funções dos Brokers**:\n",
    "1. **Armazenamento de Partições**:\n",
    "   - Cada broker armazena **partições** de diferentes tópicos. Um tópico é dividido em várias partições, que são distribuídas entre os brokers do cluster.\n",
    "   \n",
    "2. **Gerenciamento de Réplicas**:\n",
    "   - Um broker pode manter a **réplica líder** de uma partição ou ser responsável por uma **réplica seguidora**. O líder gerencia as operações de leitura e escrita, enquanto as réplicas seguidoras mantêm cópias dos dados para garantir resiliência.\n",
    "\n",
    "3. **Distribuição de Carga**:\n",
    "   - O Kafka distribui as partições entre os brokers, permitindo processamento paralelo e escalabilidade. Isso impede que um broker fique sobrecarregado.\n",
    "\n",
    "4. **Tolerância a Falhas**:\n",
    "   - Se um broker falhar, um broker que contenha uma réplica da partição falhada assume automaticamente o papel de líder, garantindo que o Kafka continue funcionando sem interrupções.\n",
    "\n",
    "5. **Coordenação do Cluster**:\n",
    "   - Um broker no cluster é designado como o **controller**, que coordena mudanças como a atribuição de partições e a eleição de novos líderes em caso de falhas.\n",
    "\n",
    "#### **Exemplo de Distribuição de Partições em um Cluster de Brokers**:\n",
    "Se você tiver um cluster com 3 brokers (B1, B2, B3) e um tópico com 4 partições, o Kafka distribuirá essas partições entre os brokers. Um exemplo seria:\n",
    "- **Partição 0**: Líder em B1, réplicas em B2 e B3.\n",
    "- **Partição 1**: Líder em B2, réplicas em B1 e B3.\n",
    "- **Partição 2**: Líder em B3, réplicas em B1 e B2.\n",
    "- **Partição 3**: Líder em B1, réplicas em B2 e B3.\n",
    "\n",
    "Isso garante que, mesmo se um broker falhar, outro broker com a réplica da partição pode assumir o controle.\n",
    "\n",
    "---\n",
    "\n",
    "### **Fator de Replicação no Apache Kafka**\n",
    "\n",
    "O **fator de replicação** é o número de cópias de cada partição de um tópico que são mantidas em diferentes brokers no cluster Kafka. Ele é essencial para garantir **alta disponibilidade** e **tolerância a falhas**.\n",
    "\n",
    "#### **Como Funciona o Fator de Replicação**:\n",
    "- **Replicação de Partições**: Para cada partição de um tópico, o Kafka cria um número de réplicas determinado pelo fator de replicação. Por exemplo, com um fator de replicação de 3, o Kafka manterá 3 cópias de cada partição em diferentes brokers.\n",
    "- **Partição Líder**: Cada partição tem uma **réplica líder**, que é responsável por gravar e ler dados. As réplicas seguidoras apenas mantêm cópias idênticas da partição e assumem o papel de líder em caso de falha.\n",
    "\n",
    "#### **Exemplos de Fator de Replicação**:\n",
    "- **Fator de Replicação = 1**: A partição tem apenas uma réplica (ela mesma). Se o broker que mantém essa partição falhar, os dados são perdidos, pois não há outras cópias.\n",
    "  \n",
    "- **Fator de Replicação = 2**: Cada partição tem uma cópia adicional. Se o broker com a partição líder falhar, uma réplica assume automaticamente.\n",
    "\n",
    "- **Fator de Replicação = 3**: Cada partição tem duas réplicas adicionais, garantindo maior tolerância a falhas. Mesmo que dois brokers falhem, ainda haverá uma cópia da partição disponível.\n",
    "\n",
    "#### **Impactos do Fator de Replicação**:\n",
    "- **Alta Disponibilidade**: Com mais réplicas, o Kafka pode continuar funcionando mesmo em caso de falhas de brokers, garantindo que as mensagens permaneçam acessíveis.\n",
    "- **Custo e Armazenamento**: Um fator de replicação maior aumenta a redundância dos dados, mas também consome mais espaço em disco e recursos de rede, pois mais brokers precisam armazenar e manter as réplicas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96a296b9-fe3e-4c1c-b440-f5872c37eb6b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Instalação do Apache Kafka\n",
    "\n",
    "1. Faça o download do Kafka no site oficial: [Apache Kafka](https://kafka.apache.org/downloads).\n",
    "   ```bash\n",
    "   sudo wget https://downloads.apache.org/kafka/3.5.2/kafka_2.12-3.5.2.tgz\n",
    "   ```\n",
    "2. Extraia os arquivos e navegue até a pasta do Kafka.\n",
    "   ```bash\n",
    "   tar -xvf kafka_2.12-3.5.2.tgz\n",
    "   ```\n",
    "   ```bash\n",
    "   cd ./kafka_2.12-3.5.2/\n",
    "   ```\n",
    "3. Inicie o Zookeeper:\n",
    "   ```bash\n",
    "   bin/zookeeper-server-start.sh config/zookeeper.properties\n",
    "   ```\n",
    "4. Inicie o Kafka:\n",
    "   ```bash\n",
    "   bin/kafka-server-start.sh config/server.properties\n",
    "   ```\n",
    "\n",
    "## Instalação da Biblioteca kafka-python\n",
    "\n",
    "Para utilizar Kafka com Python, instale a biblioteca `kafka-python`:\n",
    "\n",
    "```bash\n",
    "pip install kafka-python\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Criando Tópicos no Kafka\n",
    "\n",
    "Para criar tópicos no Kafka, você pode utilizar a linha de comando após iniciar o Kafka e o Zookeeper.\n",
    "\n",
    "\n",
    "```bash\n",
    "bin/kafka-topics.sh --create --topic meu-topico --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1\n",
    "```\n",
    "\n",
    "- **`--topic meu-topico`**: Nome do tópico.\n",
    "- **`--bootstrap-server localhost:9092`**: Endereço do servidor Kafka.\n",
    "- **`--partitions 3`**: Define 3 partições.\n",
    "- **`--replication-factor 1`**: Define o fator de replicação.\n",
    "\n",
    "## Verificando a Criação do Tópico:\n",
    "\n",
    "```bash\n",
    "bin/kafka-topics.sh --describe --topic meu-topico --bootstrap-server localhost:9092\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Criando um Produtor Kafka em Python\n",
    "\n",
    "\n",
    "```python\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Função de serialização para converter em bytes\n",
    "def serializer(message):\n",
    "    return json.dumps(message).encode('utf-8')\n",
    "\n",
    "# Criando o produtor\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=['localhost:9092'],  # Endereço do Kafka\n",
    "    value_serializer=serializer  # Serializando mensagens\n",
    ")\n",
    "\n",
    "# Enviando mensagens\n",
    "for i in range(10):\n",
    "    message = {'numero': i, 'mensagem': f\"Mensagem {i}\"}\n",
    "    producer.send('meu-topico', value=message)\n",
    "    print(f\"Mensagem enviada: {message}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "# Fecha o produtor\n",
    "producer.close()\n",
    "```\n",
    "\n",
    "Neste exemplo:\n",
    "- **`bootstrap_servers`** define o endereço do servidor Kafka (local).\n",
    "- **`value_serializer`** converte as mensagens Python em JSON.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Criando um Consumidor Kafka em Python\n",
    "\n",
    "\n",
    "```python\n",
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "\n",
    "# Função de desserialização para converter bytes em dicionário Python\n",
    "def deserializer(message):\n",
    "    return json.loads(message.decode('utf-8'))\n",
    "\n",
    "# Criando o consumidor\n",
    "consumer = KafkaConsumer(\n",
    "    'meu-topico',  # Nome do tópico\n",
    "    bootstrap_servers=['localhost:9092'],  # Endereço do Kafka\n",
    "    auto_offset_reset='earliest',  # Lê a partir do início do tópico\n",
    "    group_id='meu-grupo',  # Define um grupo de consumidores\n",
    "    value_deserializer=deserializer  # Desserializa as mensagens\n",
    ")\n",
    "\n",
    "# Lendo mensagens\n",
    "for message in consumer:\n",
    "    print(f\"Mensagem recebida: {message.value}\")\n",
    "\n",
    "# Fecha o consumidor quando terminar\n",
    "consumer.close()\n",
    "```\n",
    "\n",
    "Neste exemplo:\n",
    "- **`group_id`** define o grupo de consumidores. Consumidores no mesmo grupo compartilham a carga de mensagens.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Criando Grupos de Consumidores\n",
    "\n",
    "Grupos de consumidores são formados automaticamente ao definir um `group_id` no consumidor. Se dois ou mais consumidores fizerem parte do mesmo grupo, as mensagens serão divididas entre eles.\n",
    "\n",
    "### Exemplo de Consumidor 1 no Grupo \"grupo-de-consumo-1\":\n",
    "\n",
    "```python\n",
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "\n",
    "# Função de desserialização\n",
    "def deserializer(message):\n",
    "    return json.loads(message.decode('utf-8'))\n",
    "\n",
    "# Criando o consumidor no grupo \"grupo-de-consumo-1\"\n",
    "consumer = KafkaConsumer(\n",
    "    'meu-topico',\n",
    "    bootstrap_servers=['localhost:9092'],\n",
    "    auto_offset_reset='earliest',\n",
    "    group_id='grupo-de-consumo-1',  # Definindo o grupo de consumidores\n",
    "    value_deserializer=deserializer\n",
    ")\n",
    "\n",
    "# Lendo mensagens\n",
    "for message in consumer:\n",
    "    print(f\"Consumidor 1 - Mensagem recebida: {message.value}\")\n",
    "\n",
    "consumer.close()\n",
    "```\n",
    "\n",
    "### Exemplo de Consumidor 2 no Mesmo Grupo:\n",
    "\n",
    "```python\n",
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "\n",
    "# Função de desserialização\n",
    "def deserializer(message):\n",
    "    return json.loads(message.decode('utf-8'))\n",
    "\n",
    "# Criando outro consumidor no mesmo grupo \"grupo-de-consumo-1\"\n",
    "consumer = KafkaConsumer(\n",
    "    'meu-topico',\n",
    "    bootstrap_servers=['localhost:9092'],\n",
    "    auto_offset_reset='earliest',\n",
    "    group_id='grupo-de-consumo-1',  # Mesmo grupo\n",
    "    value_deserializer=deserializer\n",
    ")\n",
    "\n",
    "# Lendo mensagens\n",
    "for message in consumer:\n",
    "    print(f\"Consumidor 2 - Mensagem recebida: {message.value}\")\n",
    "\n",
    "consumer.close()\n",
    "```\n",
    "\n",
    "- Os dois consumidores estão no grupo `grupo-de-consumo-1` e compartilharão as mensagens do tópico `meu-topico`. Cada consumidor processará uma parte das mensagens com base nas partições do tópico.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "AULA_6_DE",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
