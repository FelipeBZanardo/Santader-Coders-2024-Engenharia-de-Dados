{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f5270fe-3a17-43ce-8f19-4c646c0f81d5",
     "showTitle": false,
     "title": ""
    },
    "id": "di_3cZgJVsDV"
   },
   "source": [
    "# Reader & Writer\n",
    "##### Objetivos\n",
    "1. Leia de arquivos CSV\n",
    "1. Leia de arquivos JSON\n",
    "1. Gravar DataFrame em arquivos\n",
    "1. Gravar DataFrame nas tabelas\n",
    "1. Gravar DataFrame em uma tabela Delta\n",
    "\n",
    "##### Métodos\n",
    "- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#input-and-output\" target=\"_blank\">DataFrameReader</a>: `csv`, `json`, `option`, `schema`\n",
    "- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#input-and-output\" target=\"_blank\">DataFrameWriter</a>: `mode`, `option`, `parquet`, `format`, `saveAsTable`\n",
    "- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html#pyspark.sql.types.StructType\" target=\"_blank\">StructType</a>: `toDDL`\n",
    "\n",
    "##### Tipos Spark\n",
    "- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#data-types\" target=\"_blank\">Types</a>: `ArrayType`, `DoubleType`, `IntegerType`, `LongType`, `StringType`, `StructType`, `StructField`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b80a67b-f6a4-4b1d-8293-04ad41425b94",
     "showTitle": false,
     "title": ""
    },
    "id": "eGJJUsMbVsDW"
   },
   "source": [
    "## DataFrameReader\n",
    "\n",
    "Interface usada para carregar um DataFrame de sistemas de armazenamento externos\n",
    "\n",
    "```\n",
    "spark.read.parquet(\"caminho/para/arquivos\")\n",
    "```\n",
    "\n",
    "DataFrameReader é acessível através do atributo SparkSession `read`. Esta classe inclui métodos para carregar DataFrames de diferentes sistemas de armazenamento externo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27a0bf06-f52d-4c32-812f-9cf3cfd27def",
     "showTitle": false,
     "title": ""
    },
    "id": "as3cjcp8VsDW"
   },
   "source": [
    "### Ler de arquivos CSV\n",
    "\n",
    "Leia do CSV com o método `csv` do DataFrameReader e as seguintes opções:\n",
    "\n",
    "Separador de tabulação, use a primeira linha como cabeçalho, infira o esquema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d7c2805-0e09-4558-8c17-609a34a12166",
     "showTitle": false,
     "title": ""
    },
    "id": "x3qhQGaRVsDX"
   },
   "outputs": [],
   "source": [
    "usersCsvPath = \"dbfs:/FileStore/shared_uploads/jorge.diaz@inf.ufrgs.br/users.csv\"\n",
    "\n",
    "usersDF = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .option(\"sep\", \",\")\n",
    "    .load(usersCsvPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bde980b-46ca-4d11-995c-02507f6caee1",
     "showTitle": false,
     "title": ""
    },
    "id": "pVostTsNVsDY",
    "outputId": "f25498db-3945-4705-dbe4-1f7dfbc362e5"
   },
   "outputs": [],
   "source": [
    "usersDF.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c53d2ad-6fb7-4374-b3ab-a41a05b83ee4",
     "showTitle": false,
     "title": ""
    },
    "id": "GMYeePUSVsDY",
    "outputId": "6a195609-133c-4430-8a91-c4dffde1cb6a"
   },
   "outputs": [],
   "source": [
    "usersDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e53f1add-b609-40fc-a427-3c5c48a1148d",
     "showTitle": false,
     "title": ""
    },
    "id": "rN-TVIanVsDY"
   },
   "source": [
    "A API Python do Spark também permite que você especifique as opções DataFrameReader como parâmetros para o método `csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b6ed3f1-8945-4fbc-86e4-887f46d9a196",
     "showTitle": false,
     "title": ""
    },
    "id": "zsEZH41hVsDY",
    "outputId": "202103b3-1746-4942-a420-f1b59b658171"
   },
   "outputs": [],
   "source": [
    "usersDF = spark.read.csv(usersCsvPath, sep=\",\", inferSchema=True, header=True)\n",
    "\n",
    "usersDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c220657-0789-4a8a-95dd-a0534627d772",
     "showTitle": false,
     "title": ""
    },
    "id": "ZKQw1a4TVsDZ"
   },
   "source": [
    "Defina manualmente o esquema criando um `StructType` com nomes de colunas e tipos de dados e leia dados mais rapidamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddddcd65-6834-40cc-b7ea-7fa4f7eb97d2",
     "showTitle": false,
     "title": ""
    },
    "id": "VyOODvQYVsDZ"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import LongType, StringType, StructType, StructField\n",
    "\n",
    "userDefinedSchema = StructType(\n",
    "    [\n",
    "        StructField(\"user_id\", StringType()),\n",
    "        StructField(\"user_first_touch_timestamp\", LongType()),\n",
    "        StructField(\"email\", StringType()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4692f5c4-9c9e-41bb-8c6e-a45a96114001",
     "showTitle": false,
     "title": ""
    },
    "id": "jTczzzAEVsDZ"
   },
   "source": [
    "Leia de CSV usando este esquema definido pelo usuário em vez de inferir o esquema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c178102-5a1f-4951-aa40-e92e418ce2ad",
     "showTitle": false,
     "title": ""
    },
    "id": "zT9159RpVsDZ",
    "outputId": "b4cab77a-e629-41d8-907f-5df172654c50"
   },
   "outputs": [],
   "source": [
    "usersDF = spark.read.csv(usersCsvPath, sep=\",\", schema=userDefinedSchema, header=True)\n",
    "\n",
    "usersDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a4fc14f-48e4-4522-8089-2f1019cfba79",
     "showTitle": false,
     "title": ""
    },
    "id": "hSPvvxapVsDZ"
   },
   "source": [
    "Como alternativa, defina o esquema usando a sintaxe <a href=\"https://en.wikipedia.org/wiki/Data_definition_language\" target=\"_blank\">linguagem de definição de dados (DDL)</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9480bb73-39ce-4a1b-a1a5-6e35d05b08f7",
     "showTitle": false,
     "title": ""
    },
    "id": "-DoD_8d2VsDZ"
   },
   "outputs": [],
   "source": [
    "DDLSchema = \"user_id string, user_first_touch_timestamp long, email string\"\n",
    "\n",
    "usersDF = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .option(\"sep\", \",\")\n",
    "    .schema(DDLSchema)\n",
    "    .load(usersCsvPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "723e02a2-48e0-453a-8d61-0f415efb9e58",
     "showTitle": false,
     "title": ""
    },
    "id": "J-PEMMboVsDZ"
   },
   "source": [
    "## DataFrameWriter\n",
    "Interface usada para gravar um DataFrame em sistemas de armazenamento externo\n",
    "\n",
    "```\n",
    "(df.write                         \n",
    "  .option(\"compression\", \"snappy\")\n",
    "  .mode(\"overwrite\")      \n",
    "  .parquet(outPath)       \n",
    ")\n",
    "```\n",
    "\n",
    "DataFrameWriter é acessível por meio do atributo SparkSession `write`. Esta classe inclui métodos para gravar DataFrames em diferentes sistemas de armazenamento externo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2206712d-ec0b-4d75-aaf4-2ee91b8e65d4",
     "showTitle": false,
     "title": ""
    },
    "id": "Kg5iedjBVsDZ"
   },
   "source": [
    "### Gravar DataFrames em arquivos\n",
    "\n",
    "Escreva `usersDF` no parquet com o método `parquet` do DataFrameWriter e as seguintes configurações:\n",
    "\n",
    "Compressão `snappy`, modo `overwrite`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c97bd187-5cfc-4928-9390-84ca62e07529",
     "showTitle": false,
     "title": ""
    },
    "id": "4bz3TuQ1VsDZ"
   },
   "outputs": [],
   "source": [
    "usersOutputPath = \"dbfs:/FileStore/shared_uploads/jchambyd@gmail.com/\" + \"users.parquet\"\n",
    "\n",
    "(\n",
    "    usersDF.write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(usersOutputPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff101e95-c51a-4b58-8c7b-647bff76b454",
     "showTitle": false,
     "title": ""
    },
    "id": "VEFC_hZ-VsDZ",
    "outputId": "4f7ecb10-8eb1-4def-f60e-8dc2ba6679bc"
   },
   "outputs": [],
   "source": [
    "usersDF2 = spark.read.parquet(usersOutputPath)\n",
    "\n",
    "display(usersDF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "414f58a2-74fa-4834-951c-3b82fbcc9d64",
     "showTitle": false,
     "title": ""
    },
    "id": "IDd7NyOaVsDa",
    "outputId": "5b2136cb-2ca4-4472-a8c4-205ad9868f6c"
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    dbutils.fs.ls(usersOutputPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06a67ff8-f6d8-43fb-b90f-77fa589a2d6e",
     "showTitle": false,
     "title": ""
    },
    "id": "-BkAALRAVsDa"
   },
   "source": [
    "Assim como o DataFrameReader, a API Python do Spark também permite que você especifique as opções do DataFrameWriter como parâmetros para o método `parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27d1af41-d10c-4978-8777-0eb575a17f7e",
     "showTitle": false,
     "title": ""
    },
    "id": "G-hBPsElVsDa"
   },
   "outputs": [],
   "source": [
    "(usersDF.write.parquet(usersOutputPath, compression=\"snappy\", mode=\"overwrite\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "405f864d-b10c-4fa9-bbbc-204aa0d0a1c0",
     "showTitle": false,
     "title": ""
    },
    "id": "M99rkTZpVsDa"
   },
   "source": [
    "### Gravar DataFrames em tabelas\n",
    "\n",
    "Escreva `eventsDF` em uma tabela usando o método DataFrameWriter `saveAsTable`\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> Isso cria uma tabela global, ao contrário da visão local criada pelo método DataFrame `createOrReplaceTempView`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b9a6c1b-89b6-446a-a452-3b4f44afee60",
     "showTitle": false,
     "title": ""
    },
    "id": "IYDchkDjVsDa"
   },
   "outputs": [],
   "source": [
    "usersDF.write.mode('overwrite').saveAsTable(\"users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "195ac7e6-f69d-4c9c-b69c-7bae2760594c",
     "showTitle": false,
     "title": ""
    },
    "id": "Lx2g9Z2zVsDa"
   },
   "outputs": [],
   "source": [
    "usersDF.createOrReplaceTempView(\"users1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "implicitDf": true
     },
     "inputWidgets": {},
     "nuid": "529a08ab-34d3-4990-9ddf-096529b7aa4f",
     "showTitle": false,
     "title": ""
    },
    "id": "JPqSvgTxVsDa",
    "outputId": "76798bc9-dfbe-4146-88cb-7bad1166bcdd"
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "select * from users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8bc6b06-8d55-42dd-9f1b-e8063bf8102a",
     "showTitle": false,
     "title": ""
    },
    "id": "hNyB0fKaVsDa"
   },
   "source": [
    "## Delta Lake\n",
    "\n",
    "Em quase todos os casos, a prática recomendada é usar o formato Delta Lake, especialmente sempre que os dados forem referenciados de um espaço de trabalho do Databricks.\n",
    "\n",
    "<a href=\"https://delta.io/\" target=\"_blank\">Delta Lake</a> é uma tecnologia de código aberto projetada para funcionar com o Spark para trazer confiabilidade aos data lakes.\n",
    "\n",
    "![delta](https://files.training.databricks.com/images/aspwd/delta_storage_layer.png)\n",
    "\n",
    "#### Principais recursos do Delta Lake\n",
    "- Transações ACID\n",
    "- Handline de metadados escalável\n",
    "- Streaming unificado e processamento em lote\n",
    "- Viagem no tempo (versionamento de dados)\n",
    "- Aplicação e evolução do esquema\n",
    "- Histórico de auditoria\n",
    "- Formato parquet\n",
    "- Compatível com Apache Spark API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "737bac08-89f6-4f81-b8a2-c51a779d843a",
     "showTitle": false,
     "title": ""
    },
    "id": "E17KgYfEVsDa"
   },
   "source": [
    "### Gravar resultados em uma tabela delta\n",
    "\n",
    "Escreva `eventsDF` com o método `save` do DataFrameWriter e as seguintes configurações: formato `delta`, modo `overwrite`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd6ed12d-5dff-4c44-893b-c52568fd2fc9",
     "showTitle": false,
     "title": ""
    },
    "id": "-8vN8XTfVsDa"
   },
   "outputs": [],
   "source": [
    "usersOutputPath = \"dbfs:/FileStore/shared_uploads/jchambyd@gmail.com/\" + \"/delta/users\"\n",
    "\n",
    "(usersDF.write.format(\"delta\").mode(\"overwrite\").save(usersOutputPath) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42baa6ae-4a44-44f5-a410-414ab98b2496",
     "showTitle": false,
     "title": ""
    },
    "id": "lIvhYl1mVsDa",
    "outputId": "b9498e64-e244-4441-9e34-c7a0a71aeb3d"
   },
   "outputs": [],
   "source": [
    "usersDFDelta = (\n",
    "    spark.read.format(\"delta\")\n",
    "    .load(usersOutputPath)\n",
    ")\n",
    "\n",
    "usersDFDelta.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f9c31f4-5bd3-4ef7-ad78-203c3acd873e",
     "showTitle": false,
     "title": ""
    },
    "id": "ZhRWgJN1VsDa"
   },
   "source": [
    "# Laboratório de dados de ingestão\n",
    "\n",
    "Leia em arquivos CSV contendo dados de produtos.\n",
    "\n",
    "##### Tarefas\n",
    "1. Leia com esquema de inferência\n",
    "2. Leia com esquema definido pelo usuário\n",
    "3. Leia com esquema como string formatada em DDL\n",
    "4. Escreva usando o formato Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9df32977-d3c2-43c0-a15f-e77731cce185",
     "showTitle": false,
     "title": ""
    },
    "id": "fQKrtfuDVsDa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1371213782836614,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Aula 04.2 - Reader & Writer",
   "notebookOrigID": 3276137106162887,
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
