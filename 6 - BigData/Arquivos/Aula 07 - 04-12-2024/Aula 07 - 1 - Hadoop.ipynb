{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6038799c",
   "metadata": {},
   "source": [
    "# Hadoop\n",
    "## O que é?\n",
    "Hadoop é um **framework** em código aberto para armazenamento e processamento distribuídos de grandes conjuntos de dados em hardware simples.\n",
    "![Hadoop](https://s3-sa-east-1.amazonaws.com/lcpi/e6813617-b661-41ae-83c5-916651ce42e9.png)\n",
    "\n",
    "## História - Linha do Tempo\n",
    "Motivado a construir um buscador complexo, que funcionasse na escala da web indexando bilhões de páginas, Doug Cutting resolveu se dedicar ao desafio iniciando seu projeto Nutch junto a Mike Cafarella, mas enfrentou alguns problemas com escalabilidade.\n",
    "\n",
    "Um artigo publicado em 2003 pelo Google abriu caminho para que a equipe do Nutch criasse uma implementação open source do GFS (Google File System).\n",
    "\n",
    "Em 2004, o Google publica o clássico artigo descrevendo seu framework MapReduce para atender às necessidades de processamento de várias máquinas das tarefas de rastreamento e índice.\n",
    "\n",
    "Em 2006, o projeto Hadoop (NDFS + MapReduce) é criado (Hadoop era o nome do elefante amarelo de pelúcia do filho de Doug).\n",
    "\n",
    "Em 2008, Hadoop se tornou um projeto independente dentro da Apache.\n",
    "\n",
    "Em 2012, a primeira versão do Apache Hadoop foi disponibilizada.\n",
    "\n",
    "Em 2013, a versão 2.2 já estava disponível.\n",
    "\n",
    "Em 2018, o Hadoop 3.0 foi lançado.\n",
    "\n",
    "Note como Hadoop foi desenvolvido de forma colaborativa, com um time dedicado ao projeto, mas fazendo uso de artigos e pesquisas de outras empresas.\n",
    "\n",
    "## Onde usar Hadoop?\n",
    "- Análise de Dados\n",
    "- Data Warehouse\n",
    "- Data Lake\n",
    "- Processamento de logs\n",
    "- Muito mais!\n",
    "\n",
    "## Características\n",
    "- Baixo custo \n",
    "- Flexibilidade de armazenamento\n",
    "- OpenSource\n",
    "- Tolerante a falha\n",
    "- Permite complexas análises de dados\n",
    "- Escalabilidade\n",
    "\n",
    "## Componentes\n",
    "- Hadoop Common\n",
    "- HDFS (Hadoop File System)\n",
    "- MapReduce\n",
    "- Yarn\n",
    "\n",
    "## Replicação\n",
    "Em um **cluster Hadoop**, os arquivos ali presentes são divididos em blocos e estes blocos são replicados nos nós de acordo com o fator de replicação definido. Em outras palavras, se em um cenário hipotético um determinado cluster possuir fator de replicação três, cada bloco de arquivo terá três cópias espalhadas em diferentes nós do cluster (desde que o cluster tenha nós suficientes). Garantindo então, alta disponibilidade, pois se um ou dois nós ficarem inativos, nenhum dado será perdido.\n",
    "Portanto, quanto maior o fator de replicação, menores os riscos de indisponibilidade; entretanto, maior será o espaço em disco ocupado.\n",
    "\n",
    "## Arquitetura\n",
    "O Hadoop é baseado em uma arquitetura Master/Slave. Um cluster Hadoop possui um único nó Master e vários nós Slaves.\n",
    "\n",
    "### Master\n",
    "É responsável por armazenar os metadados associados aos seus nós slaves no rack do qual faz parte.\n",
    "\n",
    "O nó principal é responsável por manter o status de seus nós slaves, estabelecendo um deles como um nó passivo, que se tornará um nó principal se, por qualquer motivo, estiver bloqueado.\n",
    "\n",
    "### Slave\n",
    "É o nó encarregado de armazenar e processar dados.\n",
    "\n",
    "## Hadoop Common\n",
    "Também conhecido como Hadoop Core, é a coleção de utilitários comuns e bibliotecas (JAR) que oferecem suporte a outros módulos Hadoop, sendo assim vital para sua inicialização e funcionamento.\n",
    "\n",
    "## HDFS\n",
    "Hadoop Distributed File System (HDFS) é o sistema de armazenamento distribuído utilizado por aplicações Hadoop. O HDFS quebra os arquivos em blocos de dados (128 MB por padrão), cria réplicas (três por padrão) e as distribui no cluster, permitindo assim computações extremamente rápidas em arquivos pequenos e em máquinas distintas. HDFS permite escalabilidade e tolerância a falhas.\n",
    "\n",
    "### Componentes\n",
    "- NameNode: Gerencia o namespace do sistema de arquivos do Hadoop.\n",
    "- DataNode: Armazena os blocos de dados em um nó.\n",
    "\n",
    "#### NameNode\n",
    "O NameNode faz a gestão do HDFS em um nó: mantém metadados, logs, adiciona, encontra, exclui e copia arquivos.\n",
    "\n",
    "- Armazena metadados.\n",
    "- Usa cache em RAM para acesso mais rápido ao metadado.\n",
    "- Não armazena dados.\n",
    "- Apenas 1 ativo por cluster.\n",
    "- Ponto único de falha sem HA (Alta Disponibilidade).\n",
    "\n",
    "#### DataNode\n",
    "O DataNode mantém dados e replica blocos.\n",
    "\n",
    "- Armazena os dados no HDFS.\n",
    "- Atende solicitações de leitura e gravação dos clientes ou NameNode.\n",
    "- Responsável por criar, excluir e replicar blocos de dados.\n",
    "- Reportar status para o NameNode (heartbeat).\n",
    "- Em caso de falta de report o nó é desativado pelo NameNode.\n",
    "- Totalmente dependente do NameNode.\n",
    "\n",
    "## Cloudera e Hortonworks\n",
    "Como todo software open-source, o *Apache Hadoop* pode ser utilizado livremente por empresas e estudantes sem custos de aquisição ou licenciamento. Entretanto, é comum que empresas se sintam mais seguras e amparadas para adotar determinada solução quando há respaldo e suporte. Com esta finalidade, duas empresas se tornaram muito importantes para o ecossistema *Hadoop*, justamente por desenvolverem produtos e prestarem serviços de suporte e capacitação.\n",
    "De forma prática, *Cloudera* e *Hortonworks* (desde 2019 subsidiária da Cloudera) disponibilizam ambientes (máquinas virtuais), com sistema operacional Linux e diversas ferramentas, incluindo o *Hadoop*, já instaladas e configuradas, tornando assim a experiência de Hadoop on-premise menos complexa.\n",
    "\n",
    "Caso busque experiência com *Hadoop* on-premise para fins educativos, uma forma mais simples que baixar e configurá-lo manualmente é através de Sandboxes (máquinas virtuais) gratuitas disponibilizadas pelas empresas mencionadas, que podem ser encontradas através do link:\n",
    "\n",
    "[Cloudera-Hortonwoks Sandbox](https://www.cloudera.com/downloads/hortonworks-sandbox/hdp.html)\n",
    "\n",
    "Além de inúmeros tutoriais em seu site oficial:\n",
    "\n",
    "[Cloudera Tutoriais](https://www.cloudera.com/tutorials.html)\n",
    "\n",
    "### Comandos\n",
    "Criar um diretório no *HDFS*:\n",
    "~~~\n",
    "hdfs dfs -mkdir <caminho até o diretório no HDFS>\n",
    "~~~\n",
    "\n",
    "Listar conteúdo de um diretório do *HDFS*:\n",
    "~~~\n",
    "hdfs dfs -ls <caminho até o diretório no HDFS>\n",
    "~~~\n",
    "\n",
    "Inserir arquivo no HDFS a partir do File System:\n",
    "~~~\n",
    "hdfs dfs -put <caminho do arquivo no File System> <caminho do diretório no HDFS>\n",
    "~~~\n",
    "\n",
    "Visualizar conteúdo de arquivos no *HDFS*:\n",
    "~~~\n",
    "hdfs dfs -cat <caminho até o arquivo no HDFS>\n",
    "hdfs dfs -tail <caminho até o arquivo no HDFS>\n",
    "~~~\n",
    "\n",
    "Mover arquivo dentro do *HDFS*:\n",
    "~~~\n",
    "hdfs dfs -mv <caminho até o arquivo no HDFS> <caminho do diretório destino no HDFS>\n",
    "~~~\n",
    "\n",
    "Copiar arquivo dentro do *HDFS*:\n",
    "~~~\n",
    "hdfs dfs -cp <caminho até o arquivo no HDFS> <caminho do diretório destino no HDFS>\n",
    "~~~\n",
    "\n",
    "Remover arquivo do *HDFS*:\n",
    "~~~\n",
    "hdfs dfs -rm <caminho até o arquivo no HDFS>\n",
    "~~~\n",
    "\n",
    "Copiar arquivo do *HDFS* para o *File System*:\n",
    "~~~\n",
    "hdfs dfs -get <caminho do arquivo no HDFS> <caminho do diretório no File System>\n",
    "~~~\n",
    "\n",
    "Localização dos blocos no *HDFS*:\n",
    "~~~\n",
    "hdfs fsck <caminho do arquivo no HDFS> -blocks -files -locations\n",
    "~~~\n",
    "\n",
    "Aumentar quantidade de réplicas:\n",
    "~~~\n",
    "hdfs dfs -setrep 2 <caminho do arquivo no HDFS>\n",
    "~~~\n",
    "\n",
    "## MapReduce\n",
    "O Hadoop **MapReduce** é um modelo de programação para criação de aplicações que processam rapidamente vastas quantidades de dados paralelamente através de grandes clusters de computadores comuns.\n",
    "\n",
    "O código ou programa a ser executado é transportado até o local do dado, para que tarefas independentes sejam executadas em cada bloco de dado (Map), e depois sejam consolidadas gerando a resposta do processamento (Reduce).\n",
    "\n",
    "O processo de forma simplificada:\n",
    "\n",
    "- Dados são divididos em blocos.\n",
    "- Divisão de problemas grandes e/ou complexos em pequenas tarefas.\n",
    "- Mapeamento é executado em paralelo nos nós.\n",
    "- Apenas quando o Mapeamento é encerrado, redução inicia, também em paralelo.\n",
    "- Fase intermediária: Shuffle (distribui as saídas dos mappers para a execução do reducer).\n",
    "- Existem tarefas que requerem apenas a etapa de Mapeamento.\n",
    "\n",
    "### Map\n",
    "Atua exclusivamente sobre um conjunto de entrada com **chaves e valores**, gerando uma lista.\n",
    "\n",
    "Características:\n",
    "- Ponto de partida.\n",
    "- Recebe cada registro dos dados de entrada como pares de chave/valor.\n",
    "- Cada Mapper é independente um do outro, permitindo paralelismo e re-execuções de tarefas.\n",
    "- Hadoop cria tarefas de Mapper para cada bloco de dados HDFS dos dados de entrada.\n",
    "- Produz uma lista de chave/valor.\n",
    "\n",
    "### Reduce\n",
    "Atua sobre os valores intermediários produzidos pelo map para, normalmente, agrupar os valores e produzir uma saída.\n",
    "\n",
    "Características:\n",
    "- Responsável por agregações, filtros e combinações diversas nos dados de entrada.\n",
    "- Executa uma função de reduce por vez.\n",
    "- Shuffle: Distribui as saídas dos mappers para a execução do reducer.\n",
    "- Sort: Ordena os registros chave/valor, agrupando pela chave.\n",
    "- Reduce: Envia os conjuntos chave/valor agrupados, filtrados ou combinados no formato de saída.\n",
    "\n",
    "### Pontos Positivos\n",
    "- Escalável.\n",
    "- Tolerante a falhas.\n",
    "- Disponibilidade.\n",
    "- Confiável.\n",
    "- Usa conceito de chave/valor.\n",
    "- Não cria gargalos na rede pois os dados não trafegam (processamento no nó).\n",
    "\n",
    "### Pontos Negativos\n",
    "MapReduce não é indicado para muitos casos, tais quais:\n",
    "- Consultas que necessitam de baixa latência.\n",
    "- Sistemas real-time.\n",
    "- Consultas em um website.\n",
    "- Processamento de pequenas tarefas.\n",
    "- Overhead para gerenciamento das tarefas.\n",
    "\n",
    "## Yarn\n",
    "O **YARN** foi introduzido no Hadoop versão 2.0 no ano de 2012 pelo Yahoo e Hortonworks. A premissa por trás do *YARN* é aliviar o *MapReduce*, assumindo a responsabilidade de gerir recursos e de agendar tarefas. O *YARN* começou a dar ao *Hadoop* a capacidade de executar tarefas sem *MapReduce* na estrutura do *Hadoop*.\n",
    "\n",
    "### Características:\n",
    "- Permite que vários aplicativos sejam executados simultaneamente no mesmo cluster compartilhado.\n",
    "- Permite que os aplicativos negociem recursos com base na necessidade.\n",
    "\n",
    "### Arquitetura\n",
    "#### Componentes:\n",
    "- ResourceManager: um por cluster (orquestrador).\n",
    "- Application Manager: gerencia atividades, otimização, distribuição de recursos.\n",
    "- NodeManager: um por nó, responsável pela execução dos Jobs.\n",
    "- Aplication Master: distribui tarefas aos containers.\n",
    "- Container: mantém as tarefas.\n",
    "\n",
    "### ResourceManager\n",
    "- Possui um agendador de nível de cluster que tem responsabilidade pela alocação de recursos para todas as tarefas em execução, de acordo com as solicitações do *Application Manager*.\n",
    "- A principal responsabilidade do *ResourceManager* é alocar recursos para os aplicativos.\n",
    "- Não é responsável pelo rastreamento do status de uma aplicação ou tarefas de monitoramento.\n",
    "- Não garante o reinício/balanceamento de tarefas no caso de falha no aplicativo ou no hardware.\n",
    "\n",
    "### NodeManager\n",
    "- Nó Slave, é executado nos worker nodes.\n",
    "- Gerencia o ciclo de vida do container e monitora o uso de recursos.\n",
    "- Executa o container com base na capacidade do nó, que é calculada com base na memória instalada e no número de núcleos da CPU.\n",
    "- Envia um sinal ao ResourceManager para atualizar seu status de integridade.\n",
    "- Envia o status para ResourceManager, que pode ser o status do nó ou o status das tarefas executadas.\n",
    "\n",
    "### Application Master\n",
    "- Biblioteca de aplicativos que gerencia cada instância de um aplicativo que é executado dentro de YARN.\n",
    "- Responsável por negociar recursos do ResourceManager na submissão do aplicativo, como memória e CPU.\n",
    "- Responsável por monitorar o status de um aplicativo e os processos de aplicativos em coordenação com o NodeManager.\n",
    "\n",
    "### Container\n",
    "- Pacote lógico de recursos em termos de memória, CPU, disco, etc.\n",
    "- Vinculado a um nó específico.\n",
    "- ResourceManager aloca dinamicamente recursos como containeres.\n",
    "- Um container concede direitos a um Application Master para usar uma quantidade específica de recursos de um host específico.\n",
    "- Application Master é considerado como o primeiro container de um aplicativo, ele gerencia a execução da lógica do aplicativo em containers alocados.\n",
    "\n",
    "### Comandos\n",
    "Os comandos YARN são invocados usando o script bin/yarn no pacote *Hadoop*.\n",
    "\n",
    "A sintaxe básica para o comando:\n",
    "~~~\n",
    "yarn [--config confdir] COMMAND COMMAND_OPTIONS\n",
    "~~~\n",
    "\n",
    "Application: lista, obter status e mata um aplicativo:\n",
    "~~~\n",
    "yarn application -list\n",
    "yarn application -status <job>\n",
    "yarn application -kill <job>\n",
    "~~~\n",
    "\n",
    "Node: lista e obter status dos nós\n",
    "~~~\n",
    "yarn node –list\n",
    "yarn node -all -list\n",
    "yarn node -status quickstart.cloudera:47512\n",
    "~~~\n",
    "\n",
    "Logs: obtém logs de um aplicativo já finalizado\n",
    "~~~\n",
    "yarn logs -applicationId <job>\n",
    "~~~\n",
    "\n",
    "Classpath: retorna o valor do classpath atual\n",
    "~~~\n",
    "yarn classpath\n",
    "~~~\n",
    "\n",
    "Version: retorna a versão atual do Cluster Yarn\n",
    "~~~\n",
    "yarn version\n",
    "~~~\n",
    "\n",
    "Top: fornece um resumo de informações:\n",
    "~~~\n",
    "yarn top\n",
    "~~~\n",
    "\n",
    "## Indicações e Bibliografia\n",
    "[Site oficial Apache Hadoop](https://hadoop.apache.org/)\n",
    "\n",
    "[Download Apache Hadoop](https://hadoop.apache.org/releases.html)\n",
    "\n",
    "[Documentação e Getting Started](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html)\n",
    "\n",
    "[O que é Hadoop?](https://databricks.com/glossary/hadoop)\n",
    "\n",
    "[Livro - Hadoop: The Definitive Guide](https://www.oreilly.com/library/view/hadoop-the-definitive/9780596521974/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
